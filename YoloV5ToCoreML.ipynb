{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/YOLOv5/blob/main/YoloV5ToCoreML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Export coreML including non-max suppression**"
      ],
      "metadata": {
        "id": "MpE_aeKo71Bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clone Yolov5 repo\n",
        "import os\n",
        "!git clone https://github.com/hietalajulius/yolov5.git\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt -r requirements-export.txt\n"
      ],
      "metadata": {
        "id": "7E5b2yK67zoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python export-nms.py --include coreml --weights yolov5n.pt\n"
      ],
      "metadata": {
        "id": "dA6zYJXC8Unu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ak1yv1IP8TW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Interference coreML model without MAC**"
      ],
      "metadata": {
        "id": "iWqpM9Yz2VHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If you use custom traned model, you can change the class labels to your own classes.You can specify as many classes as you like.\n",
        "classLabels = [\"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
        "numberOfClassLabels = len(classLabels)\n",
        "outputSize = numberOfClassLabels + 5"
      ],
      "metadata": {
        "id": "AKkDtPvrD5qr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True) \n",
        "\n",
        "# Change --weiths path to the path to your own checkpoint \n",
        "!python export.py --weights /content/yolov5/yolov5s.pt --include \"coreml\"\n",
        "# After run this, mlmodel saved in the directory same with the weight/"
      ],
      "metadata": {
        "id": "ZLh2PI5fAPi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just run to define the decode function\n",
        "import torch\n",
        "# classLabels = [f\"label{i}\" for i in range(80)]\n",
        "numberOfClassLabels = len(classLabels)\n",
        "outputSize = numberOfClassLabels + 5\n",
        "\n",
        "#  Attention: Some models are reversed!\n",
        "reverseModel = False\n",
        "\n",
        "strides = [8, 16, 32]\n",
        "if reverseModel:\n",
        "    strides.reverse()\n",
        "featureMapDimensions = [640 // stride for stride in strides]\n",
        "\n",
        "anchors = ([10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [\n",
        "           116, 90, 156, 198, 373, 326])  # Take these from the <model>.yml in yolov5\n",
        "if reverseModel:\n",
        "    anchors = anchors[::-1]\n",
        "\n",
        "anchorGrid = torch.tensor(anchors).float().view(3, -1, 1, 1, 2)\n",
        "\n",
        "def make_grid(nx, ny):\n",
        "    yv, xv = torch.meshgrid([torch.arange(ny), torch.arange(nx)])\n",
        "    return torch.stack((xv, yv), 2).view((ny, nx, 2)).float()\n",
        "\n",
        "def addExportLayerToCoreml(builder):\n",
        "    '''\n",
        "    Adds the yolov5 export layer to the coreml model\n",
        "    '''\n",
        "    outputNames = [output.name for output in builder.spec.description.output]\n",
        "\n",
        "    for i, outputName in enumerate(outputNames):\n",
        "        # formulas: https://github.com/ultralytics/yolov5/issues/471\n",
        "        builder.add_activation(name=f\"sigmoid_{outputName}\", non_linearity=\"SIGMOID\",\n",
        "                               input_name=outputName, output_name=f\"{outputName}_sigmoid\")\n",
        "\n",
        "        ### Coordinates calculation ###\n",
        "        # input (1, 3, nC, nC, 85), output (1, 3, nC, nC, 2) -> nC = 640 / strides[i]\n",
        "        builder.add_slice(name=f\"slice_coordinates_xy_{outputName}\", input_name=f\"{outputName}_sigmoid\",\n",
        "                          output_name=f\"{outputName}_sliced_coordinates_xy\", axis=\"width\", start_index=0, end_index=2)\n",
        "        # x,y * 2\n",
        "        builder.add_elementwise(name=f\"multiply_xy_by_two_{outputName}\", input_names=[\n",
        "                                f\"{outputName}_sliced_coordinates_xy\"], output_name=f\"{outputName}_multiplied_xy_by_two\", mode=\"MULTIPLY\", alpha=2)\n",
        "        # x,y * 2 - 0.5\n",
        "        builder.add_elementwise(name=f\"subtract_0_5_from_xy_{outputName}\", input_names=[\n",
        "                                f\"{outputName}_multiplied_xy_by_two\"], output_name=f\"{outputName}_subtracted_0_5_from_xy\", mode=\"ADD\", alpha=-0.5)\n",
        "        grid = make_grid(\n",
        "            featureMapDimensions[i], featureMapDimensions[i]).numpy()\n",
        "        # x,y * 2 - 0.5 + grid[i]\n",
        "        builder.add_bias(name=f\"add_grid_from_xy_{outputName}\", input_name=f\"{outputName}_subtracted_0_5_from_xy\",\n",
        "                         output_name=f\"{outputName}_added_grid_xy\", b=grid, shape_bias=grid.shape)\n",
        "        # (x,y * 2 - 0.5 + grid[i]) * stride[i]\n",
        "        builder.add_elementwise(name=f\"multiply_xy_by_stride_{outputName}\", input_names=[\n",
        "                                f\"{outputName}_added_grid_xy\"], output_name=f\"{outputName}_calculated_xy\", mode=\"MULTIPLY\", alpha=strides[i])\n",
        "\n",
        "        # input (1, 3, nC, nC, 85), output (1, 3, nC, nC, 2)\n",
        "        builder.add_slice(name=f\"slice_coordinates_wh_{outputName}\", input_name=f\"{outputName}_sigmoid\",\n",
        "                          output_name=f\"{outputName}_sliced_coordinates_wh\", axis=\"width\", start_index=2, end_index=4)\n",
        "        # w,h * 2\n",
        "        builder.add_elementwise(name=f\"multiply_wh_by_two_{outputName}\", input_names=[\n",
        "                                f\"{outputName}_sliced_coordinates_wh\"], output_name=f\"{outputName}_multiplied_wh_by_two\", mode=\"MULTIPLY\", alpha=2)\n",
        "        # (w,h * 2) ** 2\n",
        "        builder.add_unary(name=f\"power_wh_{outputName}\", input_name=f\"{outputName}_multiplied_wh_by_two\",\n",
        "                          output_name=f\"{outputName}_power_wh\", mode=\"power\", alpha=2)\n",
        "        # (w,h * 2) ** 2 * anchor_grid[i]\n",
        "        anchor = anchorGrid[i].expand(-1, featureMapDimensions[i],\n",
        "                                      featureMapDimensions[i], -1).numpy()\n",
        "        builder.add_load_constant_nd(\n",
        "            name=f\"anchors_{outputName}\", output_name=f\"{outputName}_anchors\", constant_value=anchor, shape=anchor.shape)\n",
        "        builder.add_elementwise(name=f\"multiply_wh_with_achors_{outputName}\", input_names=[\n",
        "                                f\"{outputName}_power_wh\", f\"{outputName}_anchors\"], output_name=f\"{outputName}_calculated_wh\", mode=\"MULTIPLY\")\n",
        "\n",
        "        builder.add_concat_nd(name=f\"concat_coordinates_{outputName}\", input_names=[\n",
        "                              f\"{outputName}_calculated_xy\", f\"{outputName}_calculated_wh\"], output_name=f\"{outputName}_raw_coordinates\", axis=-1)\n",
        "        builder.add_scale(name=f\"normalize_coordinates_{outputName}\", input_name=f\"{outputName}_raw_coordinates\",\n",
        "                          output_name=f\"{outputName}_raw_normalized_coordinates\", W=torch.tensor([1 / 640]).numpy(), b=0, has_bias=False)\n",
        "\n",
        "        ### Confidence calculation ###\n",
        "        builder.add_slice(name=f\"slice_object_confidence_{outputName}\", input_name=f\"{outputName}_sigmoid\",\n",
        "                          output_name=f\"{outputName}_object_confidence\", axis=\"width\", start_index=4, end_index=5)\n",
        "        builder.add_slice(name=f\"slice_label_confidence_{outputName}\", input_name=f\"{outputName}_sigmoid\",\n",
        "                          output_name=f\"{outputName}_label_confidence\", axis=\"width\", start_index=5, end_index=0)\n",
        "        # confidence = object_confidence * label_confidence\n",
        "        builder.add_multiply_broadcastable(name=f\"multiply_object_label_confidence_{outputName}\", input_names=[\n",
        "                                           f\"{outputName}_label_confidence\", f\"{outputName}_object_confidence\"], output_name=f\"{outputName}_raw_confidence\")\n",
        "\n",
        "        # input: (1, 3, nC, nC, 85), output: (3 * nc^2, 85)\n",
        "        builder.add_flatten_to_2d(\n",
        "            name=f\"flatten_confidence_{outputName}\", input_name=f\"{outputName}_raw_confidence\", output_name=f\"{outputName}_flatten_raw_confidence\", axis=-1)\n",
        "        builder.add_flatten_to_2d(\n",
        "            name=f\"flatten_coordinates_{outputName}\", input_name=f\"{outputName}_raw_normalized_coordinates\", output_name=f\"{outputName}_flatten_raw_coordinates\", axis=-1)\n",
        "\n",
        "    builder.add_concat_nd(name=\"concat_confidence\", input_names=[\n",
        "                          f\"{outputName}_flatten_raw_confidence\" for outputName in outputNames], output_name=\"raw_confidence\", axis=-2)\n",
        "    builder.add_concat_nd(name=\"concat_coordinates\", input_names=[\n",
        "                          f\"{outputName}_flatten_raw_coordinates\" for outputName in outputNames], output_name=\"raw_coordinates\", axis=-2)\n",
        "\n",
        "    builder.set_output(output_names=[\"raw_confidence\", \"raw_coordinates\"], output_dims=[\n",
        "                       (25200, numberOfClassLabels), (25200, 4)])"
      ],
      "metadata": {
        "id": "Hpigyc_5Fbri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just run to define the NMS function\n",
        "\n",
        "def createNmsModelSpec(nnSpec):\n",
        "    '''\n",
        "    Create a coreml model with nms to filter the results of the model\n",
        "    '''\n",
        "    nmsSpec = ct.proto.Model_pb2.Model()\n",
        "    nmsSpec.specificationVersion = 4\n",
        "\n",
        "    # Define input and outputs of the model\n",
        "    for i in range(2):\n",
        "        nnOutput = nnSpec.description.output[i].SerializeToString()\n",
        "\n",
        "        nmsSpec.description.input.add()\n",
        "        nmsSpec.description.input[i].ParseFromString(nnOutput)\n",
        "\n",
        "        nmsSpec.description.output.add()\n",
        "        nmsSpec.description.output[i].ParseFromString(nnOutput)\n",
        "\n",
        "    nmsSpec.description.output[0].name = \"confidence\"\n",
        "    nmsSpec.description.output[1].name = \"coordinates\"\n",
        "\n",
        "    # Define output shape of the model\n",
        "    outputSizes = [numberOfClassLabels, 4]\n",
        "    for i in range(len(outputSizes)):\n",
        "        maType = nmsSpec.description.output[i].type.multiArrayType\n",
        "        # First dimension of both output is the number of boxes, which should be flexible\n",
        "        maType.shapeRange.sizeRanges.add()\n",
        "        maType.shapeRange.sizeRanges[0].lowerBound = 0\n",
        "        maType.shapeRange.sizeRanges[0].upperBound = -1\n",
        "        # Second dimension is fixed, for \"confidence\" it's the number of classes, for coordinates it's position (x, y) and size (w, h)\n",
        "        maType.shapeRange.sizeRanges.add()\n",
        "        maType.shapeRange.sizeRanges[1].lowerBound = outputSizes[i]\n",
        "        maType.shapeRange.sizeRanges[1].upperBound = outputSizes[i]\n",
        "        del maType.shape[:]\n",
        "\n",
        "    # Define the model type non maximum supression\n",
        "    nms = nmsSpec.nonMaximumSuppression\n",
        "    nms.confidenceInputFeatureName = \"raw_confidence\"\n",
        "    nms.coordinatesInputFeatureName = \"raw_coordinates\"\n",
        "    nms.confidenceOutputFeatureName = \"confidence\"\n",
        "    nms.coordinatesOutputFeatureName = \"coordinates\"\n",
        "    nms.iouThresholdInputFeatureName = \"iouThreshold\"\n",
        "    nms.confidenceThresholdInputFeatureName = \"confidenceThreshold\"\n",
        "    # Some good default values for the two additional inputs, can be overwritten when using the model\n",
        "    nms.iouThreshold = 0.4\n",
        "    nms.confidenceThreshold = 0.25\n",
        "    nms.stringClassLabels.vector.extend(classLabels)\n",
        "\n",
        "    return nmsSpec\n"
      ],
      "metadata": {
        "id": "g9rgzl0_DrxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just run to combine the model added decode and the NMS.\n",
        "def combineModelsAndExport(builderSpec, nmsSpec, fileName, quantize=False):\n",
        "    '''\n",
        "    Combines the coreml model with export logic and the nms to one final model. Optionally save with different quantization (32, 16, 8) (Works only if on Mac Os)\n",
        "    '''\n",
        "    try:\n",
        "        print(f'Combine CoreMl model with nms and export model')\n",
        "        # Combine models to a single one\n",
        "        pipeline = ct.models.pipeline.Pipeline(input_features=[(\"image\", ct.models.datatypes.Array(3, 460, 460)),\n",
        "                                                               (\"iouThreshold\", ct.models.datatypes.Double(\n",
        "                                                               )),\n",
        "                                                               (\"confidenceThreshold\", ct.models.datatypes.Double())], output_features=[\"confidence\", \"coordinates\"])\n",
        "\n",
        "        # Required version (>= ios13) in order for mns to work\n",
        "        pipeline.spec.specificationVersion = 4\n",
        "\n",
        "        pipeline.add_model(builderSpec)\n",
        "        pipeline.add_model(nmsSpec)\n",
        "\n",
        "        pipeline.spec.description.input[0].ParseFromString(\n",
        "            builderSpec.description.input[0].SerializeToString())\n",
        "        pipeline.spec.description.output[0].ParseFromString(\n",
        "            nmsSpec.description.output[0].SerializeToString())\n",
        "        pipeline.spec.description.output[1].ParseFromString(\n",
        "            nmsSpec.description.output[1].SerializeToString())\n",
        "\n",
        "        # Metadata for the model‚\n",
        "        pipeline.spec.description.input[\n",
        "            1].shortDescription = \"(optional) IOU Threshold override (Default: 0.6)\"\n",
        "        pipeline.spec.description.input[\n",
        "            2].shortDescription = \"(optional) Confidence Threshold override (Default: 0.4)\"\n",
        "        pipeline.spec.description.output[0].shortDescription = u\"Boxes \\xd7 Class confidence\"\n",
        "        pipeline.spec.description.output[\n",
        "            1].shortDescription = u\"Boxes \\xd7 [x, y, width, height] (relative to image size)\"\n",
        "        pipeline.spec.description.metadata.versionString = \"1.0\"\n",
        "        pipeline.spec.description.metadata.shortDescription = \"yolov5\"\n",
        "        pipeline.spec.description.metadata.author = \"Leon De Andrade\"\n",
        "        pipeline.spec.description.metadata.license = \"\"\n",
        "\n",
        "        model = ct.models.MLModel(pipeline.spec)\n",
        "        model.save(fileName)\n",
        "\n",
        "        if quantize:\n",
        "            fileName16 = fileName.replace(\".mlmodel\", \"_16.mlmodel\")\n",
        "            modelFp16 = ct.models.neural_network.quantization_utils.quantize_weights(\n",
        "                model, nbits=16)\n",
        "            modelFp16.save(fileName16)\n",
        "\n",
        "            fileName8 = fileName.replace(\".mlmodel\", \"_8.mlmodel\")\n",
        "            modelFp8 = ct.models.neural_network.quantization_utils.quantize_weights(\n",
        "                model, nbits=8)\n",
        "            modelFp8.save(fileName8)\n",
        "\n",
        "        print(f'CoreML export success, saved as {fileName}')\n",
        "    except Exception as e:\n",
        "        print(f'CoreML export failure: {e}')"
      ],
      "metadata": {
        "id": "gq8rtvsbEDYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You need specify the path to your model that converted and saved in the same folder of your weight file.\n",
        "import coremltools as ct\n",
        "mlmodel = ct.models.MLModel(\"/content/yolov5/yolov5s.mlmodel\")"
      ],
      "metadata": {
        "id": "eUthrL2h-CEZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a0df268-f465-421b-8cd7-e2cdf00c31b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TensorFlow version 2.9.2 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.8.0 is the most recent version that has been tested.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Just run to get the mlmodel spec.\n",
        "spec = mlmodel.get_spec()\n",
        "builder = ct.models.neural_network.NeuralNetworkBuilder(spec=spec)\n",
        "spec.description"
      ],
      "metadata": {
        "id": "DRZi7EcuxCTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fdbae7b-da8b-436c-c0ec-fcacde65f7fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "input {\n",
              "  name: \"image\"\n",
              "  type {\n",
              "    imageType {\n",
              "      width: 640\n",
              "      height: 640\n",
              "      colorSpace: RGB\n",
              "    }\n",
              "  }\n",
              "}\n",
              "output {\n",
              "  name: \"var_904\"\n",
              "  type {\n",
              "    multiArrayType {\n",
              "      dataType: FLOAT32\n",
              "    }\n",
              "  }\n",
              "}\n",
              "metadata {\n",
              "  userDefined {\n",
              "    key: \"com.github.apple.coremltools.source\"\n",
              "    value: \"torch==1.12.1+cu113\"\n",
              "  }\n",
              "  userDefined {\n",
              "    key: \"com.github.apple.coremltools.version\"\n",
              "    value: \"6.0\"\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MLdTrf4W6R70",
        "outputId": "bf132df4-68b0-4e23-edcf-c8b401068476",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<coremltools.models.neural_network.builder.NeuralNetworkBuilder at 0x7f2387495250>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TP0Mn3Z7607M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}